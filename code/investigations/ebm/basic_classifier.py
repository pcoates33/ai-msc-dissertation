# Attempt to generate a fairly basic image classifier using a ConvNet.
# Use the images generated by shapes.generate_shape
# These are 480 x 640

from shapes import create_batch
import numpy as np
import torch
import torch.nn as nn
import torchvision
import time

# Define the convnet
class BasicClassifier(nn.Module):

    def __init__(self, *args, **kwargs) -> None:
        super().__init__(*args, **kwargs)
        self.pool = nn.MaxPool2d(2, 2) 
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.conv2 = nn.Conv2d(6, 8, 5)
        self.conv3 = nn.Conv2d(8, 4, 3)
        self.fc1 = nn.Linear(17556, 120)
        self.fc2 = nn.Linear(120, 60)
        self.fc3 = nn.Linear(60, 3)

    def forward(self, x):
        x = self.pool(nn.functional.relu(self.conv1(x)))
        # conv1 output will be 6,476,636
        # pool reduces that to 6,238,318
        x = self.pool(nn.functional.relu(self.conv2(x)))
        # conv2 output will be 8,234,314
        # pool reduces that to 8,117,157
        x = self.pool(nn.functional.relu(self.conv3(x)))
        # conv2 output will be 4,115,155
        # pool reduces that to 4,57,77
        x = torch.flatten(x)
        # should now be 17556
        x = nn.functional.relu(self.fc1(x))
        # And now 120
        x = nn.functional.relu(self.fc2(x))
        # Now 60
        x = self.fc3(x)
        # Now 3
        return x


if __name__ == "__main__":
    # main function

    # create a convnet
    net = BasicClassifier()

    # using Cross Entropy 
    critereon = nn.CrossEntropyLoss()
    optimiser = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

    # Need to transform image to tensor
    transformer = torchvision.transforms.Compose([
        torchvision.transforms.ToTensor()
    ])
    # Temp added to check memory usage
    batch_size = 5
    batch = create_batch(batch_size)
    inputs = create_batch(batch_size)
    img_count = 0
    # train the network
    for epoch in range(1000):

        running_loss = 0.0
        
        # batch = create_batch(batch_size)
        for shape_img, shape_label in batch:
            img_count += 1
            # switch labels from a single value to an array with one value set
            labels = torch.tensor(np.zeros(3))
            labels[shape_label['shape_type_idx']] = 1.0

            # zero parameter gradients
            optimiser.zero_grad()

            # forward + backward + optimise
            shape_tensor = transformer(shape_img)
            outputs = net.forward(shape_tensor)
            loss = critereon(outputs, labels)
            loss.backward()
            optimiser.step()

            running_loss += loss.item()
        
        # See how many we get right
        match = 0
        test_images = [transformer(img) for img, _ in inputs]
        outputs = net(test_images)
        # inputs = create_batch(batch_size)
        for img, label in inputs:
            actual = label['shape_type_idx']
            output = net(transformer(img))
            predicted = torch.argmax(output).item()
            # If the actual type is over 0.5 then it's the most likely.
            if actual == predicted:
                match += 1

        # print statistics
        time_now = time.strftime('%H:%M:%S')
        print(f'{time_now} [epoch:{epoch}] total images = {img_count} : Running loss for last {batch_size} images = {running_loss:.3f}. Test matched {match} of {len(inputs)} ')
        running_loss = 0.0

    print('Finished training.')
    torch.save(net.state_dict(), './basic_classifier_net.pth')