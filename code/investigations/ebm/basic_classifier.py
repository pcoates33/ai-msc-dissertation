# Attempt to generate a fairly basic image classifier using a ConvNet.
# Use the images generated by shapes.generate_shape
# These are 480 x 640

from shapes import ShapeBuilder
import multiprocessing as mp
import numpy as np
import torch
import torch.nn as nn
import torchvision
import time

# Define the convnet
class BasicClassifier(nn.Module):

    def __init__(self, *args, **kwargs) -> None:
        super().__init__(*args, **kwargs)
        self.pool = nn.MaxPool2d(2, 2) 
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.conv2 = nn.Conv2d(6, 8, 5)
        self.conv3 = nn.Conv2d(8, 4, 3)
        self.fc1 = nn.Linear(17556, 120)
        self.fc2 = nn.Linear(120, 60)
        self.fc3 = nn.Linear(60, 3)

    def forward(self, x):
        # x is expected to be a list of images - all wrapped up in a single tensor
        x = self.pool(nn.functional.relu(self.conv1(x)))
        # conv1 output will be 6,476,636
        # pool reduces that to 6,238,318
        x = self.pool(nn.functional.relu(self.conv2(x)))
        # conv2 output will be 8,234,314
        # pool reduces that to 8,117,157
        x = self.pool(nn.functional.relu(self.conv3(x)))
        # conv2 output will be 4,115,155
        # pool reduces that to 4,57,77
        x = torch.flatten(x, 1) # Don't flatten 1st dimension as we want to flatten each image separately
        # should now be 17556
        x = nn.functional.relu(self.fc1(x))
        # And now 120
        x = nn.functional.relu(self.fc2(x))
        # Now 60
        x = self.fc3(x)
        # Now 3
        return x


def build_expected(shape_type_idx):
    expected = torch.tensor(np.zeros(3))
    expected[shape_type_idx] = 1.0
    return expected


if __name__ == "__main__":
    # main function

    # create a convnet
    net = BasicClassifier()

    # using Cross Entropy 
    critereon = nn.CrossEntropyLoss()
    optimiser = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

    # Need to transform image to tensor
    transformer = torchvision.transforms.Compose([
        torchvision.transforms.ToTensor()
    ])

    # Use separate process to generate the shapes.
    batch_size = 50
    mini_batch_size = 4
    q = mp.Queue()
    shape_builder = ShapeBuilder(q, batch_size)
    shape_builder.daemon = True
    shape_builder.start()
    
    img_count = 0
    # train the network
    for epoch in range(1000):

        running_loss = 0.0

        # wait for the shape_builder to finish, then get the shapes from the queue.
        shape_builder.join(timeout=5)
        batch = q.get(timeout=5)

        # kick off another thread to build more shapes.
        shape_builder = ShapeBuilder(q, batch_size)
        shape_builder.daemon = True
        shape_builder.start()
   
        img_end = 0
        # batch = create_batch(batch_size)
        while img_end < batch_size:
            img_start = img_end
            img_end = min(img_start + mini_batch_size, batch_size)
            
            shape_images = [transformer(img) for img, label in batch[img_start:img_end]]
            # switch labels from a single value to an array with one value set
            shape_labels = [build_expected(label['shape_type_idx']) for img, label in batch[img_start:img_end]]
            
            img_count += img_end - img_start
            
            # zero parameter gradients
            optimiser.zero_grad()

            # forward + backward + optimise
            shape_images = torch.stack(shape_images)
            outputs = net.forward(shape_images)
            labels = torch.stack(shape_labels)
            loss = critereon(outputs, labels)
            loss.backward()
            optimiser.step()

            running_loss += loss.item()
        
        # See how many we get right
        match = 0
        # inputs = create_batch(batch_size)
        
        shape_builder.join(timeout=5)
        inputs = q.get(timeout=5)

        # kick off another 
        # TODO : add a check for last time around the loop - we don't need to build another set then.
        shape_builder = ShapeBuilder(q, batch_size)
        shape_builder.daemon = True
        shape_builder.start()

        test_imgs = [transformer(img) for img, label in inputs]
        labels = torch.as_tensor([label['shape_type_idx'] for _, label in inputs])
        test_imgs = torch.stack(test_imgs)

        outputs = net(test_imgs)

        _, predicted = torch.max(outputs.data, 1)
        match = (predicted == labels).sum().item()
        
        # for img, label in inputs:
        #     actual = label['shape_type_idx']
        #     output = net(transformer(img))
        #     predicted = torch.argmax(output).item()
        #     # If the actual type is over 0.5 then it's the most likely.
        #     if actual == predicted:
        #         match += 1

        # print statistics
        time_now = time.strftime('%H:%M:%S')
        print(f'{time_now} [epoch:{epoch}] total images = {img_count} : Running loss for last {batch_size} images = {running_loss:.3f}. Test matched {match} of {len(inputs)} ')
        running_loss = 0.0

    print('Finished training.')
    torch.save(net.state_dict(), './basic_classifier_net.pth')